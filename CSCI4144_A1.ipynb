{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Fangzheng-Chen/PlacesProject/blob/master/CSCI4144_A1.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "G0hRtlzOPtAT"
      },
      "id": "G0hRtlzOPtAT",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "id": "481d4af2-8abe-4bed-a104-b42e95892d5d",
      "metadata": {
        "tags": [],
        "id": "481d4af2-8abe-4bed-a104-b42e95892d5d"
      },
      "source": [
        "<img src=\"https://cdn.dal.ca/about-dal/history-tradition/logo-seal/_jcr_content/contentPar/staticimage.adaptive.full.high.png/1654529048363.png\" alt=\"Dalogo\" width=\"200\"/>\n",
        "\n",
        "# CSCI 4144 -  Data Mining and Data Warehousing\n",
        "# Assignment 1 - Basic Techniques\n",
        "\n",
        "**Due:** 3 February, 19h AT\n",
        "\n",
        "**Your name:** \\[Fangzheng Chen\\]  \n",
        "**Your Banner ID:** \\[B00848440\\]  \n",
        "**Your NetID:** \\[fn241880@dal.ca\\]"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "da2f420d-0f47-496a-8cc8-86418f948117",
      "metadata": {
        "id": "da2f420d-0f47-496a-8cc8-86418f948117"
      },
      "source": [
        "### Assessment\n",
        "\n",
        "***!This cell is completed only by your marker!***\n",
        "\n",
        "\n",
        "| #  | Section       |Mark | Out of  |  Comments |\n",
        "|----|---------------|-----|---------|-----------|\n",
        "| 1  | Section 1     |     | /25     |           |\n",
        "| 2  | Section 2     |     | /22     |           |\n",
        "| 3  | Bonus         |     | /5      |           |\n",
        "| -  | TOTAL         |     | /47     |           |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e3d03226-b673-4385-a334-02b7f858122a",
      "metadata": {
        "id": "e3d03226-b673-4385-a334-02b7f858122a"
      },
      "source": [
        "The main purpose of this assignment is to get familiar with processes of constructing and using a data warehouse. There are two sections: the first focuses on simple data loading and cleaning with simple data, and the second focuses on more complex data. In both cases, we will use publicly available datasets focused in the healthcare domain."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "32344d85-3987-4a71-a279-26029e66a67a",
      "metadata": {
        "id": "32344d85-3987-4a71-a279-26029e66a67a"
      },
      "outputs": [],
      "source": [
        "# import any libraries here\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import scipy\n",
        "from fitter import Fitter, get_common_distributions\n",
        "\n",
        "# TODO: add any additional libraries here\n",
        "\n",
        "# your code should run in Python3.9"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3aaf1d2-5cba-4007-af7a-3870f97c2559",
      "metadata": {
        "id": "d3aaf1d2-5cba-4007-af7a-3870f97c2559"
      },
      "source": [
        "## Section 1 - Data cleaning and ETL\n",
        "\n",
        "A [Notifiable disease](https://en.wikipedia.org/wiki/Notifiable_disease#Canada) is any disease that, by law, must be reported to government authorities. Aggregating data on these diseases allows the authorities to monitor their development, and provides early warning of possible outbreaks. The [Canadian Notifiable Disease Surveillance System](https://diseases.canada.ca/notifiable/) is a searchable database tool provided by the Public Health Agency of Canada. \n",
        "\n",
        "In this Section, we will practice cleaning some small, simple datasets.\n",
        "\n",
        "### Dataset\n",
        "\n",
        "The data for this section come from [Nova Scotia's Open Data Portal](https://data.novascotia.ca/) under the [Nova Scotia Open Government Licence](http://novascotia.ca/opendata/licence.asp). Specifically:\n",
        "\n",
        "1. [Notifiable Diseases Counts and Rates By Zone 2014-2017](https://data.novascotia.ca/Health-and-Wellness/Notifiable-Diseases-Counts-and-Rates-By-Zone-2014-/36ek-n7n8), and\n",
        "2. [Notifiable Diseases Counts and Rates By Sex 2014-2017](https://data.novascotia.ca/Health-and-Wellness/Notifiable-Diseases-Counts-and-Rates-By-Sex-2014-2/hgpa-vixp)\n",
        "\n",
        "The two files are in the [CSV](https://www.w3schools.com/python/pandas/pandas_csv.asp) file format, with a single header row and the following fields (Zone and Sex only appear in their respective file):\n",
        "\n",
        "| Field                       | Type      | Description |\n",
        "|-----------------------------|-----------|-------------|\n",
        "| Zone                        | Text      | One of four non-overlapping regions, or the aggregate 'Nova Scotia'      |\n",
        "| Sex                         | Text      | Traditional binary labels, or the aggregate 'All'       |\n",
        "| Year                        | Int       | The year in the Common Era |\n",
        "| Disease                     | Text      | The name of the disease. Additional information on the diseases can be found [here](https://novascotia.ca/dhw/cdpc/cdc/). |\n",
        "| Number of Cases             | Int       | The number of cases in the indicated region, for the indicated year |\n",
        "| Rate per 100,000 population | Float     | The rate per 100,000 population in the indicated region, for the indicated year |\n",
        "\n",
        "\n",
        "Public government data are less likely to contain errors that require cleaning or correction, so we have artificially corrupted the data for this assignment using a Python script. Specifically, we have made the following corruptions:\n",
        "\n",
        "1. **Removal**. We have randomly removed data in individual cells. Fields may be empty, have some indicative label such as 'Null', or some other corruption indicating deletion. To mimic real-world scenarios, we cannot tell you what all of these corruptions may be.\n",
        "2. **Range errors**. We have given some numeric data impossibly small values.\n",
        "3. **Spelling**. We have introduced spelling mistakes using the [corrupted-text](https://pypi.org/project/corrupted-text/) library to text fields.\n",
        "4. **Duplicates**. We have randomly repeated some rows\n",
        "5. **Shuffle**. We have randomly shuffled rows subsequent to the above corruptions.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "Our tasks in this section are to clean the data, perform simple 'sanity checks', and display some simple visualizations. This is essentially a simplified view into an ETL process. You can use the clean data provided directly by the Nova Scotia government at the links above to validate your work, but your code must work assuming you don't have acss to the clean gold standard versions. Also note that we are fortunate that these data have, essentially, error-correcting codes built in, since 'All' data should be the sum of Male and Female data, and 'Nova Scotia' data should be the sum of all the individual regions.\n",
        "\n",
        "Complete each of the code cells below according to the instructions in the comments.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a0bfc5a1-fa8e-4479-908c-edf9c12d9ad9",
      "metadata": {
        "id": "a0bfc5a1-fa8e-4479-908c-edf9c12d9ad9"
      },
      "outputs": [],
      "source": [
        "# 1. load the corrupted data in a Pandas DataFrame. \n",
        "#     Note that we will test your code on another corruption of the same dataset, \n",
        "#        so you should not hardcode to your version. \n",
        "#     Note that you can load your own corruptions for testing, \n",
        "#        but you should submit a notebook with our original corruptions.\n",
        "\n",
        "# Note: you are encouraged to download these files either from here or from Brightspace directly and to use them locally,\n",
        "#       as long as your code works for the markers (e.g., do not hardcode local paths in submission).\n",
        "urlSex  = 'https://dal.brightspace.com/d2l/common/viewFile.d2lfile/Database/MTQ0Nzc0MDc/Notifiable_Diseases_Counts_and_Rates_By_Sex_2014-2017.corrupt.csv?ou=250788'\n",
        "urlZone = 'https://dal.brightspace.com/d2l/common/viewFile.d2lfile/Database/MTQ0Nzc0MDg/Notifiable_Diseases_Counts_and_Rates_By_Zone_2014-2017.corrupt.csv?ou=250788'\n",
        "\n",
        "# TODO YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "73bbc077-f83b-4961-a28b-e0aefb2f3cf2",
      "metadata": {
        "id": "73bbc077-f83b-4961-a28b-e0aefb2f3cf2"
      },
      "outputs": [],
      "source": [
        "# 2. sort both DataFrames by Year, then by Disease, then by either Zone or Sex. \n",
        "#    I.e., all data for 2014 comes before all data from 2015; \n",
        "#          within 2014, all data for 'Acquired Immune Deficiency Syndrome' comes before all data for 'Hepatitis B - Acute', \n",
        "#          and so on \n",
        "\n",
        "# TODO YOUR CODE GOES HERE\n",
        "\n",
        "# TODO: print the two sorted Pandas DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b70fcccd-9864-411c-9613-efbbf8b4c0e2",
      "metadata": {
        "id": "b70fcccd-9864-411c-9613-efbbf8b4c0e2"
      },
      "outputs": [],
      "source": [
        "# 3. identify duplicate entries\n",
        "\n",
        "# TODO YOUR CODE GOES HERE\n",
        "\n",
        "# TODO: for each DataFrame, print a list of row indices for all duplicates except the first. \n",
        "#        E.g., if row 52 is a duplicate of row 51, and row 201 is a duplicate of row 200, \n",
        "#              print [52,201]\n",
        "\n",
        "# TODO: remove the duplicate rows from the two DataFrames"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b220e373-ad9e-4f8f-80c1-616f526cce7a",
      "metadata": {
        "id": "b220e373-ad9e-4f8f-80c1-616f526cce7a"
      },
      "outputs": [],
      "source": [
        "# 4. identify cells with missing data\n",
        "\n",
        "# TODO YOUR CODE GOES HERE\n",
        "# TODO: print a list of indices for the corrupted cells. \n",
        "#        E.g., if cells [9, 3] and [20, 1] are missing or have null-like labels, print [[9,3],[20,1]]\n",
        "\n",
        "# TODO: replace these elements with np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e58d82ca-01a2-415d-8027-c36edb9f85b1",
      "metadata": {
        "id": "e58d82ca-01a2-415d-8027-c36edb9f85b1"
      },
      "outputs": [],
      "source": [
        "# 5. identify cells with out-of-bounds errors\n",
        "\n",
        "# TODO YOUR CODE GOES HERE\n",
        "# TODO: print a list of indices for the corrupted cells. \n",
        "#        E.g., if cells [9, 3] and [20, 1] have out-of-bounds data, print [[9,3],[20,1]]\n",
        "\n",
        "# TODO: replace these elements with np.nan"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b7233277-11b9-4caa-b2ed-6a2a6d6e786d",
      "metadata": {
        "id": "b7233277-11b9-4caa-b2ed-6a2a6d6e786d"
      },
      "outputs": [],
      "source": [
        "# 6. perform additional internal 'sanity check' within each data set\n",
        "#    For each year, the total reported number of each disease (i.e., in the 'All' or 'Nova Scotia' rows)\n",
        "#    should be the sum of the component parts.\n",
        "\n",
        "# TODO: make a list of all unique disease names\n",
        "diseaseNames = ''\n",
        "\n",
        "# TODO: your code goes here\n",
        "\n",
        "for year in range(2014,2018):\n",
        "    for dataType in ['Sex', 'Zone']:\n",
        "        for diseaseName in diseaseNames:\n",
        "            \n",
        "            # TODO: if the reported total number of cases is not the same as the sums of the component parts \n",
        "            #       (e.g., if the reported 'All' is not the sum of the male and female cases), then\n",
        "            print( year + ' ' + diseaseName + ' does not sum correctly for '+ dataType +'!')\n",
        "        "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "53fb5fae-5d78-4829-8bf8-803895b0cd62",
      "metadata": {
        "id": "53fb5fae-5d78-4829-8bf8-803895b0cd62"
      },
      "outputs": [],
      "source": [
        "# 7. perform additional external 'sanity check' across both data sets\n",
        "#    For each year, the total number of each disease should be the same in each dataset \n",
        "#    (i.e., the 'All' Sex rows should match the 'Nova Scotia' Zone rows)\n",
        "\n",
        "# TODO: make a list of all unique disease names\n",
        "diseaseNames = ''\n",
        "\n",
        "# TODO: your code goes here\n",
        "\n",
        "for year in range(2014,2018):\n",
        "    for diseaseName in diseaseNames:\n",
        "            \n",
        "        # TODO: if the reported total number of cases is not the same across datasets \n",
        "        #       (i.e., if the reported 'All' in Sex is not the same as the reported 'Nova Scotia' in Zone), then\n",
        "        print( year + ' ' + diseaseName + ' does not match across datasets!')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "11681ef0-6cf9-4e81-98d7-f0569d61922b",
      "metadata": {
        "id": "11681ef0-6cf9-4e81-98d7-f0569d61922b"
      },
      "outputs": [],
      "source": [
        "# 8. plot the total number of cases for each year, for the disease indicated in 'diseaseName'\n",
        "#    Use the matplotlib scatter function (https://matplotlib.org/stable/plot_types/basic/scatter_plot.html)\n",
        "\n",
        "diseaseName = ''\n",
        "\n",
        "# TODO: your code goes here. Be sure to handle potential errors. \n",
        "#       Add appropriate axis labels and title."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f2978e1c-7ff3-4276-9844-a17b38d70dfa",
      "metadata": {
        "id": "f2978e1c-7ff3-4276-9844-a17b38d70dfa"
      },
      "source": [
        "### Assessment for section 1\n",
        "\n",
        "***!This cell is completed only by your marker!***\n",
        "\n",
        "\n",
        "| #  | Task          |Mark | Out of  |  Comments |\n",
        "|----|---------------|-----|---------|-----------|\n",
        "| 1  | Load          |     | /2      |           |\n",
        "| 2  | Sort          |     | /5      |           |\n",
        "| 3  | Duplicates    |     | /3      |           |\n",
        "| 4  | Missing       |     | /5      |           |\n",
        "| 5  | Out-of-bounds |     | /2      |           |\n",
        "| 6  | Intra check   |     | /3      |           |\n",
        "| 7  | Inter check   |     | /3      |           |\n",
        "| 8  | Plot          |     | /2      |           |\n",
        "| -  | TOTAL         |     | /25     |           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f31a02c2-bfcb-44bf-8973-c8af5c0d0da8",
      "metadata": {
        "id": "f31a02c2-bfcb-44bf-8973-c8af5c0d0da8"
      },
      "source": [
        "## Section 2 - Data imputation, reduction, and basic analysis\n",
        "\n",
        "The novel coronavirus disease 2019 ([COVID-19](https://www.canada.ca/en/public-health/services/diseases/coronavirus-disease-covid-19.html)) is a contagious disease caused by the severe acute respiratory syndrome coronavirus 2 (SARS-CoV-2). The first known case was identified in December 2019. The disease quickly spread worldwide, resulting in the COVID-19 pandemic. \n",
        "\n",
        "In this Section, we will use some simple data science techniques to 1) identify similarities between countries, 2) identify covariates that relate to \n",
        "\n",
        "### Dataset: Our World in Data COVID \n",
        "\n",
        "The data for this section come [Our World in Data](https://ourworldindata.org/coronavirus), i.e., from their GitHub [repository](https://github.com/owid/covid-19-data/tree/master/public/data). More specifically, the that team aggregated data from multiple sources such as [Johns Hopkins University](https://github.com/CSSEGISandData/COVID-19), various official national sources, the United Nations, the World Bank, Global Burden of Disease, and others. It is released under the [Creative Commons BY License](https://creativecommons.org/licenses/by/4.0/).\n",
        "\n",
        "There are 67 features in the dataset, only some of which we will use. For information on these, consult https://github.com/owid/covid-19-data/tree/master/public/data.\n",
        "\n",
        "### Tasks\n",
        "\n",
        "Our task is to look for simple patterns in the COVID data. First, we will 'fill in the blanks' in the data through imputation, project the data down into fewer dimensions, perform some simple distribution fitting to the data, compute measures of entropy, and finally look for features that are highly related or informative.\n",
        "\n",
        "Complete each of the code cells below according to the instructions in the comments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8e18b043-8ec8-43bd-9229-2b5f4b8d2832",
      "metadata": {
        "id": "8e18b043-8ec8-43bd-9229-2b5f4b8d2832"
      },
      "outputs": [],
      "source": [
        "# 1. Impute mising data\n",
        "#    - Select only countries with a population >= 30 million\n",
        "#    - Use the KNNImputer from scikit-learn, with k=3 nearest neighbours, to impute missing\n",
        "#      numeric data among the selected countries\n",
        "#    - Your resulting DataFrame should have all text and numeric fields below\n",
        "\n",
        "# Note: you are encouraged to download this file either from here or from Brightspace directly and to use it locally,\n",
        "#       as long as your code works for the markers (e.g., do not hardcode local paths in submission).\n",
        "urlCOVID = 'https://dal.brightspace.com/d2l/le/dropbox/250788/174362/DownloadAttachment?fid=14594172'\n",
        "\n",
        "text_fields = ['location','date']\n",
        "numeric_fields = ['new_cases_per_million', 'new_deaths_per_million', \n",
        "                  'people_vaccinated_per_hundred','people_fully_vaccinated_per_hundred', \n",
        "                  'stringency_index', 'population_density', 'median_age', \n",
        "                  'gdp_per_capita','extreme_poverty','cardiovasc_death_rate',\n",
        "                  'hospital_beds_per_thousand','life_expectancy','human_development_index',\n",
        "                  'population']\n",
        "\n",
        "# TODO: your code goes here\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "adc2445e-1db4-4927-8e0f-af419c47b9e9",
      "metadata": {
        "id": "adc2445e-1db4-4927-8e0f-af419c47b9e9"
      },
      "outputs": [],
      "source": [
        "# 2. Extract the top 10 principal components\n",
        "\n",
        "# TODO: your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c528189b-b296-4422-a095-36cb48974211",
      "metadata": {
        "id": "c528189b-b296-4422-a095-36cb48974211"
      },
      "outputs": [],
      "source": [
        "# 3. For each numeric field separately, using the imputed data:\n",
        "#        a) identify best distributions using the Fitter library \n",
        "#           (https://pypi.org/project/fitter/) \n",
        "#           Only consider the subset in common_distributions\n",
        "#        b) print the summary for each fit using the built in fitter summary() function\n",
        "#        c) plot the data using the Fitter.hist() function\n",
        "#        d) plot the density function using the Fitter.plot_pdf() function\n",
        "\n",
        "common_distributions = get_common_distributions()\n",
        "# TODO: your code goes here"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c71f794-a039-4f52-96b0-afdef7ec65d4",
      "metadata": {
        "id": "2c71f794-a039-4f52-96b0-afdef7ec65d4"
      },
      "outputs": [],
      "source": [
        "# 4. For each numeric field separately, using the imputed data:\n",
        "#        a) Using the best distribution from the previous cell, _and all of its parameters_,\n",
        "#           print the results of the associated entropy() method in scipy.stats\n",
        "#           e.g., if the best distribution found is chi2, call\n",
        "#                 scipy.stats.chi2.entropy( mydf, loc=myloc, scale=myscale ) for \n",
        "#                 computed values of mydf, myloc, and myscale\n",
        "#        b) bin the data for that field once into 100 equal-width bins and\n",
        "#           once into 100 equal-frequency bins. Store the proportional frequency of\n",
        "#           each bin, relative to the total number of samples, in p_equalWidth and \n",
        "#           p_equalFreq, below\n",
        "#        c) compute and print the Shannon entropy on each of p_equalWidth and p_equalFreq using\n",
        "#           https://docs.scipy.org/doc/scipy/reference/generated/scipy.stats.entropy.html\n",
        "#\n",
        "#    In the Markdown cell below, describe in your own words what differences you observe\n",
        "#    in the results between the distribution-based and the two Shannon-based entropy methods.\n",
        "#    Which numeric field is the most informative? Which is the least informative?\n",
        "\n",
        "# TODO: your code goes here\n",
        "\n",
        "#    discretize data in two methods - equal probability vs equal size.\n",
        "#    compute entropy.\n",
        "p_equalWidth = np.zeros(100)\n",
        "p_equalFreq  = np.zeros(100)\n",
        "\n",
        "# TODO: your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e6c1afab-6eee-45de-aa01-9b403ee5cd31",
      "metadata": {
        "id": "e6c1afab-6eee-45de-aa01-9b403ee5cd31"
      },
      "source": [
        "**TODO**: Enter your discussion for task 4 of Section 2 here, in no more than 10 sentences."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b901f053-7c19-42a4-bcc9-f04522b26710",
      "metadata": {
        "id": "b901f053-7c19-42a4-bcc9-f04522b26710"
      },
      "outputs": [],
      "source": [
        "# 5. Identify variables that relate to important COVID outcomes\n",
        "#    For each of 'new_cases_per_million' and 'new_deaths_per_million', compute Pearson\n",
        "#    correlation (using https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.corr.html)\n",
        "#    with that field and all other numeric fields\n",
        "#\n",
        "#        For the 4 features most correlated with the outcome of interest, plot a 5x5 \n",
        "#        SeaBorn PairGrid (https://seaborn.pydata.org/generated/seaborn.PairGrid.html) with\n",
        "#        scatter in the upper matrix, histograms on the diagonal, and kde plots on the \n",
        "#        lower matrix, as in:\n",
        "#\n",
        "#               g = sns.PairGrid(penguins, diag_sharey=False)\n",
        "#               g.map_upper(sns.scatterplot)\n",
        "#               g.map_lower(sns.kdeplot)\n",
        "#               g.map_diag(sns.histplot)\n",
        "#\n",
        "#    In the Markdown cell below, list the features that are most correlated with \n",
        "#    'new_cases_per_million' and 'new_deaths_per_million'. Are these the same that \n",
        "#    were 'informative' in task 4 of Section 2? Why or why not?\n",
        "#\n",
        "# TODO: your code goes here"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "67a8f1ad-447d-4532-aabb-133c9087c789",
      "metadata": {
        "id": "67a8f1ad-447d-4532-aabb-133c9087c789"
      },
      "source": [
        "**TODO**: Enter your discussion for task 5 of Section 2 here, in no more than 5 sentences."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "995be54e-58bd-4f8f-b150-961bc7a6a9b0",
      "metadata": {
        "id": "995be54e-58bd-4f8f-b150-961bc7a6a9b0"
      },
      "source": [
        "### Assessment for section 2\n",
        "\n",
        "***!This cell is completed only by your marker!***\n",
        "\n",
        "\n",
        "| #  | Task          |Mark | Out of  |  Comments |\n",
        "|----|---------------|-----|---------|-----------|\n",
        "| 1  | Impute        |     | /4      |           |\n",
        "| 2  | PCA           |     | /1      |           |\n",
        "| 3  | Fit           |     | /4      |           |\n",
        "| 4  | Entropy       |     | /8      |           |  \n",
        "| 5  | Correlations  |     | /5      |           |\n",
        "| -  | TOTAL         |     | /22     |           |"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "86da773e-0411-4b4d-af9f-186ce7b3b2e8",
      "metadata": {
        "id": "86da773e-0411-4b4d-af9f-186ce7b3b2e8"
      },
      "source": [
        "## Bonus [5 Marks]\n",
        "\n",
        "- We will give up to 5 bonus marks for innovative work going substantially beyond the minimal requirements. \n",
        "- These marks can make up for marks lost in other sections of the assignment, but your overall mark for this assignment cannot exceed 100%. \n",
        "- You may decide to pursue any number of tasks of your own design related to this assignment, although you should consult with the instructor or the lead TA before embarking on such exploration, and the value of bonus work is left to the discretion of the markers. \n",
        "- Be sure to document your work sufficiently for the markers to understand what you're doing. You can add additional Code or MarkDown cells below, as necessary.\n",
        "- Certainly, the rest of the assignment takes higher priority. \n",
        "\n",
        "Some ideas:\n",
        "\n",
        "1. **Outlier corruptions**. Introduce some outliers to the data in Section 1, and write a program that can identify and potentially remove those outliers. Experiment with different methods of ourlier detection, compare them, and report your results.\n",
        "2. **Spelling correction**. Correct the spelling errors in Section 1, or at least identify which text fields have errors in them. \n",
        "3. **Imputation**. Perform imputation for the missing Nova Scotia data in Section 1.\n",
        "4. **Better correlations**. Are there better ways of assessing correlation between variables across time series, in Section 2?\n",
        "5. **Differential entropy**. Consider reading scientific articles on differential entropy, using the method from scipy.stats.differential_entropy, and comparing against the results you obtained in Section 2. How do you expect the results to differ? How are the results different?\n",
        "6. **Analysis of principal components**. Repeat some of the analysis you did with the original features (e.g., entropy) but with the principal components you extracted. What do you observe across the principal components? How are the results different than with the original features?\n",
        "7. **General improvements**. Are there any approaches prescribed in this assignment that would have been more appropriate or meaningful?\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7490853a-0f35-4d8a-b978-a8b0b1bd8ffd",
      "metadata": {
        "id": "7490853a-0f35-4d8a-b978-a8b0b1bd8ffd"
      },
      "outputs": [],
      "source": [
        "# BONUS Section\n",
        "\n",
        "# TODO YOUR CODE GOES HERE"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "798df400-f3c3-4a95-9fc4-6675f5f3d21f",
      "metadata": {
        "id": "798df400-f3c3-4a95-9fc4-6675f5f3d21f"
      },
      "source": [
        "**TODO**: Any discussion for the Bonus section goes here. Feel free to add additional cells below this one, and before the assessment cell. "
      ]
    },
    {
      "cell_type": "markdown",
      "id": "26e09f78-1a73-4428-a4d1-584dfc2b10c7",
      "metadata": {
        "id": "26e09f78-1a73-4428-a4d1-584dfc2b10c7"
      },
      "source": [
        "### Assessment for bonus section\n",
        "\n",
        "***!This cell is completed only by your marker!***\n",
        "\n",
        "\n",
        "| #  | Task          |Mark | Out of  |  Comments |\n",
        "|----|---------------|-----|---------|-----------|\n",
        "| 1  | Bonus         |     | /5      |           |\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "047e7ee2-416b-4130-947d-c1878d4f8e65",
      "metadata": {
        "tags": [],
        "id": "047e7ee2-416b-4130-947d-c1878d4f8e65"
      },
      "source": [
        "## Academic Integrity\n",
        "\n",
        "The following is template information. If there is any ambiguity or contradiction with official Dalhousie University policies, those Dalhousie University policies take effect.\n",
        "\n",
        "At Dalhousie University, we respect the values of academic integrity: honesty, trust, fairness, responsibility, and respect. As a student, adherence to the values of academic integrity and related policies is a requirement of being part of the academic community at Dalhousie University.\n",
        "\n",
        "### What does academic integrity mean?\n",
        "\n",
        "Academic integrity means being honest in the fulfillment of your academic responsibilities thus establishing mutual trust. Fairness is essential to the interactions of the academic community and is achieved through respect for the opinions and ideas of others. Violations of intellectual honesty are oﬀensive to the entire academic community, not just to the individual faculty member and students in whose class an oﬀence occur (See the Dalhousie Secretariat's page on [Academic Integrity](https://www.dal.ca/dept/university_secretariat/academic-integrity.html).\n",
        "\n",
        "### How can you achieve academic integrity?\n",
        "\n",
        "- Make sure you understand Dalhousie’s policies on academic integrity.\n",
        "- Give appropriate credit to the sources used in your assignment such as written or oral work, computer codes/programs, artistic or architectural works, scientific projects,  performances,  web page designs, graphical representations, diagrams, videos, and images. Use [RefWorks](http://www.library.dal.ca/How/RefWorks) to keep track of your research and edit and format bibliographies in the citation style required by the instructor.\n",
        "- Do not download the work of another from the Internet and submit it as your own.\n",
        "- Do not submit work that has been completed through collaboration or previously submitted for another assignment without permission from your instructor.\n",
        "- Do not write an examination or test for someone else.\n",
        "- Do not falsify data or lab results.\n",
        "\n",
        "These examples should be considered only as a guide and not an exhaustive list.\n",
        "\n",
        "### What will happen if an allegation of an academic oﬀence is made against you?\n",
        "\n",
        "The teaching team is required to report any suspected oﬀence. The full process is outlined in the Discipline flow chart, which can be found [here](https://cdn.dal.ca/content/dam/dalhousie/pdf/dept/university_secretariat/FDPflowchartSEpt2016.pdf) and includes the following:\n",
        "\n",
        "1. Each Faculty has an Academic Integrity Oﬃcer (AIO) who receives allegations from instructors.\n",
        "2. The AIO decides whether to proceed with the allegation and you will be notified of the process.\n",
        "3. If the case proceeds, you will receive an INC (incomplete) grade until the matter is resolved.\n",
        "4. If you are found guilty of an academic oﬀence, a penalty will be assigned ranging from a warning to a suspension or expulsion from the University and can include a notation on your transcript, failure of the assignment or failure of the course. All penalties are academic in nature.\n",
        "\n",
        "### Where can you turn for help?\n",
        "\n",
        "- If you are ever unsure about ANYTHING, contact the teaching team or lead instructor.\n",
        "- The Academic Integrity website (http://academicintegrity.dal.ca) has links to policies, definitions, online tutorials, tips on citing and paraphrasing.\n",
        "- The Writing Center provides assistance with proofreading, writing styles, citations.\n",
        "- Dalhousie Libraries have workshops, online tutorials, citation guides, Assignment Calculator, RefWorks, etc.\n",
        "- The Dalhousie Student Advocacy Service assists students with academic appeals and student discipline procedures.\n",
        "- The Senate Oﬃce provides links to a list of Academic Integrity Oﬃcers, discipline flow chart, and Senate Discipline Committee.\n",
        "\n",
        "\n",
        "## Academic offenses\n",
        "\n",
        "There is a zero-tolerance policy on academic offenses such as plagiarism or inappropriate collaboration. By submitting your solution for this assignment, you acknowledge that the code submitted is your own work. You also agree that your code may be submitted to plagiarism detection software (such as MOSS) unless you have notified the teaching team otherwise, in writing, before the submission deadline. Any suspected act of plagiarism will be reported to the Faculty’s Academic Integrity Officer in accordance with Dalhousie University’s regulations regarding Academic Integrity. Please note that:\n",
        "\n",
        "1. The assignments are individual assignments. You can discuss the problems with your friends/classmates, but you need to write your program by yourself. There should not be much similarity in terms of coding. \n",
        "2. When you refer to some online resources to complete your program, you need to understand the mechanism, then write your own code. Your code should not be similar to the online resources. In addition, you should cite the sources via comments in your program.\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.6"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}